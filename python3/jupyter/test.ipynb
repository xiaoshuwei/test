{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://dump:111@127.0.0.1:6001/mo_doc_embedding\", echo=True)\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"select 'hello world'\"))\n",
    "    print(result.all())\n",
    "# Connect to the database\n",
    "connection = pymysql.connect(host='127.0.0.1',\n",
    "                             port=6001,\n",
    "                             user='dump',\n",
    "                             password='111',\n",
    "                            #  database='db',\n",
    "                            #  charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "# conn = MySQLdb.connect(host=\"127.0.0.1\", port=6001, user=\"dump\", passwd=\"111\")\n",
    "# cursor = conn.cursor()\n",
    "cursor.execute(\"create database if not exists ai_doc;use ai_doc;\")\n",
    "cursor.execute('''\n",
    "    create table if not exists mo_doc_embedding(\n",
    "   `id` varchar(256) not null comment 'uuid primary key with id',\n",
    "   `doc_embedding_vector` vecf64(1536) not null comment 'doc embedding vector',\n",
    "   `text_chunk` text not null comment 'chunk text',\n",
    "   `payload` text not null comment 'payload data',\n",
    "   primary key (`id`)\n",
    "    );\n",
    "''')\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import REAL, Column, String, Table, create_engine, insert, text, DOUBLE\n",
    "from sqlalchemy.dialects.postgresql import ARRAY, JSON, TEXT\n",
    "conn = MySQLdb.connect(host=\"127.0.0.1\", port=6001, user=\"dump\", passwd=\"111\",db=\"ai_doc\")\n",
    "cursor = conn.cursor()\n",
    "table_name = \"test\"\n",
    "chunks_table = Table(\n",
    "    table_name,\n",
    "    Column(\"id\", TEXT, primary_key=True),\n",
    "    Column(\"embedding\", ARRAY(DOUBLE,dimensions=3)),\n",
    "    Column(\"document\", String, nullable=True),\n",
    "    Column(\"metadata\", JSON, nullable=True),\n",
    "    extend_existing=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "chunks_table_data = []\n",
    "with self.engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        for document, metadata, chunk_id, embedding in zip(\n",
    "            texts, metadatas, ids, embeddings\n",
    "        ):\n",
    "            chunks_table_data.append(\n",
    "                {\n",
    "                    \"id\": chunk_id,\n",
    "                    \"embedding\": embedding,\n",
    "                    \"document\": document,\n",
    "                    \"metadata\": metadata,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Execute the batch insert when the batch size is reached\n",
    "            if len(chunks_table_data) == batch_size:\n",
    "                conn.execute(insert(chunks_table).values(chunks_table_data))\n",
    "                # Clear the chunks_table_data list for the next batch\n",
    "                chunks_table_data.clear()\n",
    "\n",
    "        # Insert any remaining records that didn't make up a full batch\n",
    "        if chunks_table_data:\n",
    "            conn.execute(insert(chunks_table).values(chunks_table_data))\n",
    "\n",
    "cursor.execute(\"insert into %s \")\n",
    "result = cursor.fetchall()\n",
    "print(result)\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import Table, Column, Integer, String, MetaData,ARRAY,DOUBLE,TEXT\n",
    "from sqlalchemy.orm import registry,sessionmaker\n",
    "from sqlalchemy.orm import DeclarativeBase\n",
    "from sqlalchemy.orm import Mapped\n",
    "from sqlalchemy.orm import mapped_column\n",
    "from typing import List\n",
    "import sqlalchemy.types as types\n",
    "import json\n",
    "import uuid\n",
    "import random\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://dump:111@127.0.0.1:6001/ai_doc\", echo=True)\n",
    "# with engine.connect() as conn:\n",
    "#     result = conn.execute(text('''\n",
    "#     create table if not exists mo_doc_embedding(\n",
    "#    `id` varchar(256) not null comment 'uuid primary key with id',\n",
    "#    `doc_embedding_vector` vecf64(5) not null comment 'doc embedding vector',\n",
    "#    `text_chunk` text not null comment 'chunk text',\n",
    "#    `payload` text not null comment 'payload data',\n",
    "#    primary key (`id`)\n",
    "# );\n",
    "#     '''))\n",
    "#     conn.commit()\n",
    "    \n",
    "class Base(DeclarativeBase):\n",
    "    pass\n",
    "\n",
    "\n",
    "class MODoubleVector(types.UserDefinedType):\n",
    "    impl = types.TEXT\n",
    "\n",
    "    cache_ok = True\n",
    "\n",
    "    def __init__(self, precision:int = None):\n",
    "        if precision == None :\n",
    "            raise ValueError(\n",
    "                \"precision is None. \"\n",
    "                \"Please input precision.\"\n",
    "            )\n",
    "        self.precision = precision\n",
    "\n",
    "    def get_col_spec(self, **kw):\n",
    "        return \"vecf64(%s)\" % self.precision\n",
    "    \n",
    "    def bind_processor(self, dialect):\n",
    "        def process(value):\n",
    "            print(type(value))\n",
    "            print(json.dumps(value,separators=(',',':')))\n",
    "            return json.dumps(value,separators=(',',':'))\n",
    "        return process\n",
    "\n",
    "    def result_processor(self, dialect, coltype):\n",
    "        def process(value):\n",
    "            print(type(value))\n",
    "            return json.loads(value)\n",
    "        return process\n",
    "\n",
    "table_name = 'mo_doc_embedding'\n",
    "# model\n",
    "class MODocEmbedding(Base):\n",
    "    __tablename__ = table_name\n",
    "    # __tablename__ = 'mo_doc_vector'\n",
    "    id:Mapped[str] = mapped_column(String(256),primary_key=True,nullable=False)\n",
    "    payload: Mapped[str] = mapped_column(TEXT)\n",
    "    doc_embedding_vector: Mapped[List[float]] = mapped_column(MODoubleVector(5),nullable=False)\n",
    "    def __init__(self, id=None, payload=None, doc_embedding_vector=None):\n",
    "        print(doc_embedding_vector,payload)\n",
    "        if id == None:\n",
    "            id = uuid.uuid4().hex\n",
    "        self.id = id\n",
    "        if doc_embedding_vector != None:\n",
    "            self.doc_embedding_vector = doc_embedding_vector\n",
    "        if payload != None:\n",
    "            self.payload = payload\n",
    "\n",
    "Base.metadata.create_all(bind=engine)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "try:\n",
    "    # for i in range(100):\n",
    "    #     user = MODocEmbedding(payload=(\"payload_%d\" % (i)),doc_embedding_vector=[random.randint(0,9),random.randint(0,9),random.randint(0,9),random.randint(0,9),random.randint(0,9)])\n",
    "    #     session.add(user)\n",
    "    # session.commit()\n",
    "    session\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    session.rollback()\n",
    "session.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user='dump'\n",
    "password='111'\n",
    "host = '127.0.0.1'\n",
    "port = '6001'\n",
    "dbname='ai_doc'\n",
    "connectionSQL = \"mysql+pymysql://%s:%s@%s:%s/%s\" % (user,password,host,port,dbname)\n",
    "print(connectionSQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "21\n",
      "23\n",
      "23\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Incorrect API key provided: sk-MDtWc***************************************HoPl. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(metadatas[\u001b[39m0\u001b[39m]))\n\u001b[1;32m     59\u001b[0m \u001b[39m# ids = mo.add_texts(texts=texts,metadatas=metadatas)\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m mo \u001b[39m=\u001b[39m Matrixone\u001b[39m.\u001b[39;49mfrom_texts(texts\u001b[39m=\u001b[39;49mdocs,metadatas\u001b[39m=\u001b[39;49mmetadatas,embedding\u001b[39m=\u001b[39;49mOpenAIEmbeddings(openai_api_key\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msk-MDtWchamqgXENQ6FTuNHT3BlbkFJgcC4WOkK1lT0Lw6eHoPl\u001b[39;49m\u001b[39m'\u001b[39;49m),host\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m127.0.0.1\u001b[39;49m\u001b[39m'\u001b[39;49m,port\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m6001\u001b[39;49m\u001b[39m'\u001b[39;49m,user\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdump\u001b[39;49m\u001b[39m'\u001b[39;49m,password\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m111\u001b[39;49m\u001b[39m'\u001b[39;49m,dbname\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmo_cloud\u001b[39;49m\u001b[39m'\u001b[39;49m,table_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtest_table_name\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     61\u001b[0m \u001b[39m# mo = Matrixone(table_name='test_table_name',embedding=TestEmbedding(),host='127.0.0.1',port='6001',user='dump',password='111',dbname='mo_cloud')\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39m# mo._new_mo_doc_embedding_table_and_registry(5)\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m# ids = mo.add_texts(texts=docs,metadatas=metadatas)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39m# for (doc,score) in results:\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39m#     print(doc,score)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/vectorstores/matrixone.py:376\u001b[0m, in \u001b[0;36mMatrixone.from_texts\u001b[0;34m(cls, texts, embedding, user, password, dbname, metadatas, host, port, table_name, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Construct Matrixone wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39mThis is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    1. Embeds documents.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39m        mo = Matrixone.from_texts(texts=texts,embedding=embedding,user=user,password=password,dbname=dbname)\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m mo \u001b[39m=\u001b[39m Matrixone(table_name\u001b[39m=\u001b[39mtable_name,embedding\u001b[39m=\u001b[39membedding,host\u001b[39m=\u001b[39mhost,port\u001b[39m=\u001b[39mport,user\u001b[39m=\u001b[39muser,password\u001b[39m=\u001b[39mpassword,dbname\u001b[39m=\u001b[39mdbname)\n\u001b[0;32m--> 376\u001b[0m mo\u001b[39m.\u001b[39;49madd_texts(texts\u001b[39m=\u001b[39;49mtexts,metadatas\u001b[39m=\u001b[39;49mmetadatas)\n\u001b[1;32m    377\u001b[0m \u001b[39mreturn\u001b[39;00m mo\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/vectorstores/matrixone.py:129\u001b[0m, in \u001b[0;36mMatrixone.add_texts\u001b[0;34m(self, texts, metadatas)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run more texts through the embeddings and add to the vectorstore.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[39m    texts: Iterable of strings to add to the vectorstore.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39m    List of ids from adding the texts into the vectorstore.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m payloads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_payloads(texts\u001b[39m=\u001b[39mtexts,metadatas\u001b[39m=\u001b[39mmetadatas)\n\u001b[0;32m--> 129\u001b[0m vectors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding\u001b[39m.\u001b[39;49membed_documents(texts\u001b[39m=\u001b[39;49mtexts)\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(vectors) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[39mreturn\u001b[39;00m []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/embeddings/openai.py:478\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \n\u001b[1;32m    468\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/embeddings/openai.py:364\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    361\u001b[0m     _iter \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size)\n\u001b[1;32m    363\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[0;32m--> 364\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[1;32m    365\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    366\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtokens[i : i \u001b[39m+\u001b[39;49m _chunk_size],\n\u001b[1;32m    367\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[1;32m    368\u001b[0m     )\n\u001b[1;32m    369\u001b[0m     batched_embeddings\u001b[39m.\u001b[39mextend(r[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    371\u001b[0m results: List[List[List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/embeddings/openai.py:107\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response)\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/embeddings/openai.py:104\u001b[0m, in \u001b[0;36membed_with_retry.<locals>._embed_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-MDtWc***************************************HoPl. You can find your API key at https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.vectorstores import Matrixone\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from typing import List\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "class TestEmbedding(Embeddings):\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        # return [random.randint(0,9),random.randint(0,9),random.randint(0,9),random.randint(0,9),random.randint(0,9)]\n",
    "        return [2,9,3,6,7]\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [\n",
    "            [random.randint(0,9),random.randint(0,9),random.randint(0,9),random.randint(0,9),random.randint(0,9)]\n",
    "            for i in texts\n",
    "        ]\n",
    "    \n",
    "test_embedding = TestEmbedding()\n",
    "\n",
    "# mo = Matrixone(table_name='test_table_name',embedding=TestEmbedding(),host='127.0.0.1',port='6001',user='dump',password='111',dbname='mo_cloud')\n",
    "# texts = []\n",
    "# metadatas = []\n",
    "# for i in range (5):\n",
    "#     texts.append('text_'+str(i))\n",
    "#     meta = {\n",
    "#         'page_content' : 'pagecontent_'+str(i),\n",
    "#         'metadata' : 'metadata_'+str(i)\n",
    "#     }\n",
    "#     metadatas.append(meta)\n",
    "\n",
    "AI_DOC_FILE_DIR = \"./ai_doc_file_dir\"\n",
    "\n",
    "ps = list(Path(AI_DOC_FILE_DIR).glob(\"**/*.md\"))\n",
    "data = []\n",
    "sources = []\n",
    "for p in ps:\n",
    "    with open(p) as f:\n",
    "        data.append(f.read())\n",
    "    sources.append(p)\n",
    "\n",
    "# Here we split the documents, as needed, into smaller chunks.\n",
    "# We do this due to the context limits of the LLMs.\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, separator=\"\\n\\n\",chunk_overlap=50)\n",
    "docs = []\n",
    "metadatas = []\n",
    "for i, d in enumerate(data):\n",
    "    splits = text_splitter.create_documents([d])\n",
    "    print(len(splits))\n",
    "    for doc in splits:\n",
    "        docs.append(str(doc.page_content))\n",
    "    metadatas.extend([{\"source\": str(sources[i])}] * len(splits))\n",
    "\n",
    "print(len(docs))\n",
    "print(len(metadatas))\n",
    "print(type(metadatas[0]))\n",
    "\n",
    "# ids = mo.add_texts(texts=texts,metadatas=metadatas)\n",
    "mo = Matrixone.from_texts(texts=docs,metadatas=metadatas,embedding=OpenAIEmbeddings(openai_api_key='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'),host='127.0.0.1',port='6001',user='dump',password='111',dbname='mo_cloud',table_name='test_table_name')\n",
    "# mo = Matrixone(table_name='test_table_name',embedding=TestEmbedding(),host='127.0.0.1',port='6001',user='dump',password='111',dbname='mo_cloud')\n",
    "# mo._new_mo_doc_embedding_table_and_registry(5)\n",
    "# ids = mo.add_texts(texts=docs,metadatas=metadatas)\n",
    "\n",
    "# results = mo.similarity_search_with_score('123')\n",
    "# for (doc,score) in results:\n",
    "#     print(doc,score)\n",
    "# results = mo.similarity_search('123')\n",
    "# for result in results:\n",
    "    # print(result)\n",
    "# print(\"\\n\\n\")\n",
    "# results = mo.max_marginal_relevance_search('123')\n",
    "# results = mo.max_marginal_relevance_search_with_score_by_vector(test_embedding.embed_query('123'))\n",
    "# for result in results:\n",
    "#     print(result)\n",
    "# mo.delete(ids=ids)\n",
    "# results = mo.similarity_search_with_score('123')\n",
    "# for (doc,score) in results:\n",
    "#     print(doc,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.matrixone import Matrixone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# frame = pd.read_csv('cu.csv')\n",
    "# baseFactor = 8.320546887000001e-07\n",
    "# sumMem = 0.0\n",
    "# sumCpu = 0.0\n",
    "# sumIn = 0.0\n",
    "# sumOut = 0.0\n",
    "# sumNetIO = 0.0\n",
    "# NetIOFactor = 1.08e-10\n",
    "# InFactor = 4e-7\n",
    "# OutFactor = 4e-7\n",
    "# MemFactor = 1.87e-24\n",
    "# CpuFactor = 1.15e-14\n",
    "# sumsCu = 0.0\n",
    "# newSumCu = 0.0\n",
    "# for index, row in frame.iterrows():\n",
    "#     stats = json.loads(row.stats)\n",
    "#     cpu = stats[1]\n",
    "#     mem = stats[2]*row.duration\n",
    "#     In  = stats[3]\n",
    "#     Out = stats[4]\n",
    "#     net = stats[5]\n",
    "#     sumCpu += cpu\n",
    "#     sumMem += mem\n",
    "#     sumIn += In\n",
    "#     sumOut += Out\n",
    "#     sumNetIO += net\n",
    "#     sumsCu += row.cu\n",
    "#     newCu = (cpu*CpuFactor+mem*MemFactor+In*InFactor+Out*OutFactor+net*NetIOFactor)/baseFactor\n",
    "#     newSumCu += newCu\n",
    "#     # print(\"newCu: \"+str(newCu)+\" oldCu: \"+str(row.cu))\n",
    "# # print(\"cpu:\"+str(sumCpu)+\" mem:\"+str(sumMem)+\" In:\"+str(sumIn)+\" Out:\"+str(sumOut)+\" NetIO:\"+str(sumNetIO))\n",
    "# sumCu = (sumCpu*CpuFactor+sumMem*MemFactor+sumIn*InFactor+sumOut*OutFactor+sumNetIO*NetIOFactor)/baseFactor\n",
    "# print(\"mo_cloud.cu SumCU: \"+str(sumCu))\n",
    "# print(\"statement_cu SumCU: \"+str(sumsCu))\n",
    "# print(\"newSumCU: \"+str(newSumCu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pymysql\n",
    "\n",
    "def calcCU(stats:list[float],duration:int) -> float:\n",
    "    NetIOFactor = 9.65e-11\n",
    "    PrivateNetIOFactor = 0\n",
    "    InFactor = 5e-6\n",
    "    OutFactor = 4e-7\n",
    "    MemFactor = 1.87e-24\n",
    "    CpuFactor = 1.15e-14\n",
    "\n",
    "    baseCPU = 4697\n",
    "    baseMemory = 1e13\n",
    "    baseS3In = 0\n",
    "    baseS3Out = 1\n",
    "    baseNetworkIO = 40000\n",
    "    basePrivateNetworkIO = 40000\n",
    "    baseNetworkConnType = 1\n",
    "\n",
    "    # calc base CU\n",
    "    baseCU = baseCPU*CpuFactor + baseMemory*MemFactor + baseS3In*InFactor + baseS3Out*OutFactor\n",
    "    baseNetWorkIOAdd = baseNetworkIO*NetIOFactor\n",
    "    if baseNetworkConnType != 1 :\n",
    "        baseNetWorkIOAdd = PrivateNetIOFactor*basePrivateNetworkIO\n",
    "    baseCU += baseNetWorkIOAdd\n",
    "    \n",
    "    # calc CU\n",
    "\n",
    "    if len(stats) < 5:\n",
    "        return None\n",
    "    if stats[0] >= 2 and len(stats) < 6:\n",
    "        return None\n",
    "    if stats[0] >= 3 and len(stats) < 7:\n",
    "        return None\n",
    "    \n",
    "    sum = stats[1]*CpuFactor + stats[2]*duration*MemFactor + stats[3]*InFactor + stats[4]*OutFactor \n",
    "    networkio = stats[5]*NetIOFactor\n",
    "    if stats[0] >= 3 and stats[6] == 1:\n",
    "        networkio = stats[5]*PrivateNetIOFactor\n",
    "    sum += networkio\n",
    "    return sum/baseCU\n",
    "\n",
    "def checkCUCalcResultRight(cu:float,calcCUResult:float)->bool:\n",
    "    return abs(cu-calcCUResult)<0.01\n",
    "\n",
    "\n",
    "def get_sql_result_as_csv(sql:str,sql_result:str,hostname:str,port:int,user:str,password:str)->None:\n",
    "    conn = pymysql.connect(host=hostname,port=port,user=user,passwd=password)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    data = cursor.fetchall()\n",
    "\n",
    "    # 将数据转换为DataFrame格式\n",
    "    df = pd.DataFrame(data, columns=[i[0] for i in cursor.description])\n",
    "    # 将数据保存到csv文件中\n",
    "    df.to_csv(sql_result, encoding='utf-8-sig', index=False)\n",
    "\n",
    "    # 关闭游标和数据库连接\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "hostname = '127.0.0.1'\n",
    "port = 6009\n",
    "user = 'dump'\n",
    "password = '111'\n",
    "\n",
    "sql_result = './sql_result.csv'\n",
    "\n",
    "sql = '''\n",
    "select cu,stats,duration \n",
    "from mo_catalog.statement_cu \n",
    "left join system.statement_info on system.statement_info.statement_id=mo_catalog.statement_cu.statement_id \n",
    "where system.statement_info.account = 'test' \n",
    "order by cu \n",
    "desc \n",
    "limit 1000;\n",
    "'''\n",
    "\n",
    "get_sql_result_as_csv(sql=sql,sql_result=sql_result,hostname=hostname,port=port,user=user,password=password)\n",
    "\n",
    "frame = pd.read_csv(sql_result)\n",
    "for index, row in frame.iterrows():\n",
    "    stats = json.loads(row.stats)\n",
    "    duration = row.duration\n",
    "    cu = row.cu\n",
    "    calcCUResult = calcCU(stats=stats,duration=duration)\n",
    "    if not checkCUCalcResultRight(cu,calcCUResult=calcCUResult):\n",
    "        print('cu:{cu},calcCU:{calcCUResult}'.format(cu=cu,calcCUResult=calcCUResult))\n",
    "    # print('cu:{cu},calcCU:{calcCUResult}'.format(cu=cu,calcCUResult=calcCUResult))\n",
    "print('check finished !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "class CUCalculator:\n",
    "    baseCPU = 4697\n",
    "    baseMemory = 1e13\n",
    "    baseS3In = 0\n",
    "    baseS3Out = 1\n",
    "    baseNetworkIO = 40000\n",
    "    basePrivateNetworkIO = 40000\n",
    "    baseNetworkConnType = 1\n",
    "    \n",
    "    baseCU = 0\n",
    "\n",
    "    NetIOFactor = 9.65e-11\n",
    "    PrivateNetIOFactor = 0\n",
    "    InFactor = 5e-6\n",
    "    OutFactor = 4e-7\n",
    "    MemFactor = 1.87e-24\n",
    "    CpuFactor = 1.15e-14\n",
    "\n",
    "    def calc_base_cu(self) -> None:\n",
    "         # calc base CU\n",
    "        self.baseCU = self.baseCPU*self.CpuFactor + self.baseMemory*self.MemFactor + self.baseS3In*self.InFactor + self.baseS3Out*self.OutFactor\n",
    "        baseNetWorkIOAdd = self.baseNetworkIO*self.NetIOFactor\n",
    "        if self.baseNetworkConnType != 1 :\n",
    "            baseNetWorkIOAdd = self.PrivateNetIOFactor*self.basePrivateNetworkIO\n",
    "        self.baseCU += baseNetWorkIOAdd\n",
    "    \n",
    "    def __init__(self,stats:list[float],duration:int,id:str) -> None:\n",
    "        if self.baseCU == 0:\n",
    "            self.calc_base_cu()\n",
    "        self.ids = [id]\n",
    "        self.duration = duration\n",
    "        if len(stats) < 5:\n",
    "            return None\n",
    "        self.version = stats[0]\n",
    "        self.cpu = stats[1]\n",
    "        self.mem = stats[2]\n",
    "        self.s3In = stats[3]\n",
    "        self.s3Out = stats[4]\n",
    "        self.networkIOResult = 0\n",
    "        if stats[0] >= 2 and len(stats) >= 6:\n",
    "            self.networkIOResult = stats[5]*self.NetIOFactor\n",
    "        if stats[0] >= 3 and len(stats) >= 7 and stats[6] == 1: # 0:Unkown 1:Internel 2:Externel\n",
    "            self.networkIOResult = stats[5]*self.PrivateNetIOFactor\n",
    "    \n",
    "    def calcCU(self)->float:\n",
    "        sum = self.cpu*self.CpuFactor + self.mem*self.duration*self.MemFactor + self.s3In*self.InFactor + self.s3Out*self.OutFactor + self.networkIOResult\n",
    "        return sum/self.baseCU\n",
    "    \n",
    "    def addOne(self,CUCalc) -> None:\n",
    "        self.cpu += CUCalc.cpu\n",
    "        self.mem += CUCalc.mem\n",
    "        self.s3In += CUCalc.s3In\n",
    "        self.s3Out += CUCalc.s3Out\n",
    "        self.networkIOResult += CUCalc.networkIOResult\n",
    "        self.ids.extend(CUCalc.ids)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return 'CUCalculator[cpu:{cpu},mem:{mem},s3In:{s3In},s3Out:{s3Out},networkIOResult:{networkIOResult},ids:{ids}]'.format(cpu=self.cpu,mem=self.mem,s3In=self.s3In,s3Out=self.s3Out,networkIOResult=self.networkIOResult,ids=self.ids)\n",
    "        \n",
    "\n",
    "\n",
    "hostname = '127.0.0.1'\n",
    "port = 6009\n",
    "user = 'dump'\n",
    "password = '111'\n",
    "\n",
    "cu_calc_time_interval = '1min' #truncate time duration\n",
    "\n",
    "sql_mo_cloud_cu_result = './sql_mo_cloud_cu_result.csv'\n",
    "sql_statement_info_result = './sql_statement_info_result.csv'\n",
    "\n",
    "sql_mo_cloud_cu = '''\n",
    "select * from mo_cloud.cu where account = 'test' order by start_time desc limit 100;\n",
    "'''\n",
    "sql_statement_info = '''\n",
    "select * from `system`.`statement_info` where response_at >= '{start_time}' and account = 'test' order by response_at desc;\n",
    "'''\n",
    "\n",
    "def get_sql_result_as_csv(sql:str,sql_result:str,hostname:str,port:int,user:str,password:str)->None:\n",
    "    conn = pymysql.connect(host=hostname,port=port,user=user,passwd=password)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    data = cursor.fetchall()\n",
    "\n",
    "    # 将数据转换为DataFrame格式\n",
    "    df = pd.DataFrame(data, columns=[i[0] for i in cursor.description])\n",
    "    # 将数据保存到csv文件中\n",
    "    df.to_csv(sql_result, encoding='utf-8-sig', index=False)\n",
    "\n",
    "    # 关闭游标和数据库连接\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "def checkCUCalcResultEqual(cuCalc:CUCalculator,cu:float) -> bool:\n",
    "    print('CUCalculator:{cuCalc}, mocloud.cu:{cu}'.format(cuCalc=cuCalc,cu=cu))\n",
    "    return abs(cuCalc.calcCU()-cu) < 0.01\n",
    "\n",
    "get_sql_result_as_csv(sql=sql_mo_cloud_cu,sql_result=sql_mo_cloud_cu_result,hostname=hostname,port=port,user=user,password=password)\n",
    "\n",
    "frame = pd.read_csv(sql_mo_cloud_cu_result)\n",
    "lastRow = frame.iloc[-1]\n",
    "\n",
    "account_map = {}\n",
    "\n",
    "for index,row in frame.iterrows():\n",
    "    start_time_map = account_map.get(row.account)\n",
    "    if start_time_map == None: \n",
    "        start_time_map = {}\n",
    "        account_map[row.account] = start_time_map\n",
    "    start_time = pd.Timestamp(datetime.datetime.strptime(row.start_time,\"%Y-%m-%d %H:%M:%S\")).floor(cu_calc_time_interval).to_pydatetime()\n",
    "    sql_type_map = start_time_map.get(start_time)\n",
    "    if sql_type_map == None:\n",
    "        sql_type_map = {}\n",
    "        start_time_map[start_time] = sql_type_map\n",
    "    sql_type_map[row.type] = row.cu\n",
    "\n",
    "get_sql_result_as_csv(sql=sql_statement_info.format(start_time=lastRow.start_time),sql_result=sql_statement_info_result,hostname=hostname,port=port,user=user,password=password)\n",
    "\n",
    "frame = pd.read_csv(sql_statement_info_result)\n",
    "\n",
    "result_account_map = {}\n",
    "\n",
    "for index,row in frame.iterrows():\n",
    "    stats = json.loads(row.stats)\n",
    "    duration = row.duration\n",
    "    t = CUCalculator(stats=stats,duration=duration,id=row.statement_id)\n",
    "    start_time_map = result_account_map.get(row.account)\n",
    "    if start_time_map == None: \n",
    "        start_time_map = {}\n",
    "        result_account_map[row.account] = start_time_map\n",
    "    start_time = pd.Timestamp(datetime.datetime.strptime(row.response_at,\"%Y-%m-%d %H:%M:%S.%f\")).floor(cu_calc_time_interval).to_pydatetime()\n",
    "    sql_type_map = start_time_map.get(start_time)\n",
    "    if sql_type_map == None:\n",
    "        sql_type_map = {}\n",
    "        start_time_map[start_time] = sql_type_map\n",
    "    CUCalc = sql_type_map.get(row.sql_source_type)\n",
    "    if CUCalc == None:\n",
    "        CUCalc = t\n",
    "    else:\n",
    "        CUCalc.addOne(t)\n",
    "    sql_type_map[row.sql_source_type] = CUCalc\n",
    "\n",
    "# check CU Result\n",
    "for account,tstart_time_map in account_map.items():\n",
    "    for start_time,tsql_type_map in tstart_time_map.items():\n",
    "        for sql_type,cu in tsql_type_map.items():\n",
    "            cuCalc = result_account_map[account][start_time][sql_type]\n",
    "            if not checkCUCalcResultEqual(cuCalc=cuCalc,cu=cu) :\n",
    "                print('Check Error: cu:{cu},CUCalc:{CUCalc}'.format(cu=cu,CUCalc=cuCalc))\n",
    "\n",
    "# finished \n",
    "print('check mo_cloud.cu finish !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "import logging\n",
    "from email.header import Header\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "b'Invalid input from 124.77.159.88 to newxmesmtplogicsvrsza12-0.qq.com.'\n",
    "class MOMAIL:\n",
    "    # mail_host = 'smtp.exmail.qq.com'\n",
    "    mail_host = 'smtp.qq.com'\n",
    "    mail_port = 465\n",
    "    # mail_username = 'no-reply@matrixonecloud.cn'\n",
    "    # mail_password = 'eGHPiCvHwjgQ4uZ6'\n",
    "    mail_username = '1216210029@qq.com'\n",
    "    mail_password = 'sxbmqpuygjvqhfgi'\n",
    "    sender = mail_username\n",
    "    receivers = ['xiaoshuwei@matrixorigin.cn']\n",
    "\n",
    "content = \"DOCUMENT DATA IMPORT FINISHED.\"\n",
    "message = MIMEText(content,'plain','utf-8')\n",
    "message['From'] = \"{}\".format(MOMAIL.sender)\n",
    "message['To'] = \",\".join(MOMAIL.receivers)\n",
    "message['Subject'] = content\n",
    "\n",
    "try:\n",
    "    smtpObj = smtplib.SMTP_SSL(host = MOMAIL.mail_host)\n",
    "    smtpObj.login(MOMAIL.mail_username,MOMAIL.mail_password)\n",
    "    smtpObj.sendmail(MOMAIL.sender, MOMAIL.receivers, message.as_string())\n",
    "    logging.info(\"DOCUMENT DATA IMPORT FINISHED. and send email finished.\")\n",
    "except smtplib.SMTPException as e:\n",
    "    logging.error(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
